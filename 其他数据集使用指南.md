# MiniOneRec 在其他数据集上的使用指南

## 概述

MiniOneRec 可以在任何包含**用户-商品交互序列**和**商品文本信息**的数据集上使用。本指南将详细说明如何准备数据并运行完整流程。

## 数据要求

### 必需的数据格式

你的数据集需要包含以下信息：

1. **商品元数据**：每个商品需要有文本描述（至少包含标题）
2. **用户交互序列**：用户与商品的交互历史（按时间排序）
3. **数据划分**：训练集、验证集、测试集

### 数据格式选项

#### 选项 1：Amazon 风格格式（推荐）

如果你的数据格式类似 Amazon 数据集，可以直接使用现有的预处理脚本。

**输入文件：**
- `metadata.json`：商品元数据（JSON Lines 格式）
  ```json
  {"asin": "B000123", "title": "商品标题", "description": "商品描述", ...}
  ```
- `reviews.json`：用户评论/交互数据（JSON Lines 格式）
  ```json
  {"reviewerID": "A1", "asin": "B000123", "unixReviewTime": 1234567890, "overall": 5.0}
  ```

#### 选项 2：自定义格式

如果你的数据格式不同，需要准备以下文件：

**1. 商品元数据文件** (`{dataset_name}.item.json`)
```json
{
  "0": {
    "title": "商品标题",
    "description": "商品描述",
    "brand": "品牌",
    "categories": "分类1,分类2"
  },
  "1": {
    "title": "另一个商品",
    ...
  }
}
```

**2. 交互数据文件** (`{dataset_name}.{split}.inter`)
```
user_id:token	item_id_list:token_seq	item_id:token
0	1 2 3	4
0	1 2 3 4	5
1	10 11	12
```

格式说明：
- 第一行是表头（必须）
- 每行：`用户ID \t 历史商品ID序列(空格分隔) \t 目标商品ID`
- 历史序列按时间顺序排列

## 完整使用流程

### 步骤 1：数据预处理

#### 1.1 如果使用 Amazon 风格数据

```bash
# 使用 amazon18_data_process.py 处理数据
bash data/amazon18_data_process.sh \
     --dataset YourDataset \
     --user_k 5 \
     --item_k 5 \
     --st_year 2017 \
     --st_month 10 \
     --ed_year 2018 \
     --ed_month 11 \
     --output_path ./data/YourDataset \
     --metadata_file path/to/metadata.json \
     --reviews_file path/to/reviews.json
```

**参数说明：**
- `--dataset`: 数据集名称
- `--user_k`, `--item_k`: K-core 过滤阈值（保留至少 K 次交互的用户/商品）
- `--st_year`, `--st_month`, `--ed_year`, `--ed_month`: 时间范围
- `--output_path`: 输出目录
- `--metadata_file`, `--reviews_file`: 元数据和评论文件路径

**输出文件：**
- `{dataset}.train.inter`: 训练集交互
- `{dataset}.valid.inter`: 验证集交互
- `{dataset}.test.inter`: 测试集交互
- `{dataset}.item.json`: 商品元数据
- `{dataset}.user2id`, `{dataset}.item2id`: ID 映射文件

#### 1.2 如果使用自定义格式

直接准备以下文件：
- `{dataset_name}.item.json`（商品元数据）
- `{dataset_name}.train.inter`（训练集）
- `{dataset_name}.valid.inter`（验证集）
- `{dataset_name}.test.inter`（测试集）

### 步骤 2：生成商品文本嵌入

将商品文本（标题+描述）编码为嵌入向量。

```bash
bash rq/text2emb/amazon_text2emb.sh \
     --dataset YourDataset \
     --root ./data/YourDataset \
     --plm_name qwen \
     --plm_checkpoint path/to/qwen/model
```

**参数说明：**
- `--dataset`: 数据集名称
- `--root`: 数据目录（包含 `.item.json` 文件）
- `--plm_name`: 预训练模型名称（如 qwen, llama）
- `--plm_checkpoint`: 预训练模型路径

**输出文件：**
- `{dataset}.emb-{plm_name}-td.npy`: 商品嵌入向量（N×D 矩阵）

### 步骤 3：构建 SID（语义 ID）

选择以下方法之一构建 SID：

#### 方法 1：RQ-VAE（推荐）

```bash
bash rq/rqvae.sh \
     --data_path ./data/YourDataset/YourDataset.emb-qwen-td.npy \
     --ckpt_dir ./output/YourDataset/rqvae \
     --lr 1e-3 \
     --epochs 10000 \
     --batch_size 20480
```

#### 方法 2：RQ-Kmeans

```bash
conda install faiss-gpu
python rq/rqkmeans_faiss.py --dataset YourDataset
```

#### 方法 3：Constrained RQ-Kmeans

```bash
pip install k_means_constrained polars
bash rq/rqkmeans_constrained.sh
```

#### 方法 4：RQ-Kmeans+（GPR 方法）

```bash
pip install k_means_constrained polars
bash rq/rqkmeans_constrained.sh
bash rq/rqkmeans_plus.sh
```

**生成索引文件：**

对于 RQ-VAE：
```bash
python rq/generate_indices.py \
     --dataset YourDataset \
     --data_dir ./data/YourDataset \
     --ckpt_dir ./output/YourDataset/rqvae
```

对于 RQ-Kmeans+：
```bash
bash rq/generate_indices_plus.sh
```

**输出文件：**
- `{dataset}.index.json`: 商品ID → SID token 列表的映射
- `{dataset}.item.json`: 商品元数据（已存在，无需重新生成）

### 步骤 4：转换数据集格式

将交互数据转换为 MiniOneRec 训练格式（包含 SID）。

```bash
python convert_dataset.py \
     --data_dir ./data/YourDataset \
     --dataset_name YourDataset \
     --output_dir ./data/YourDataset/formatted \
     --category YourCategory \
     --max_valid_samples 10000 \
     --max_test_samples 10000
```

**参数说明：**
- `--data_dir`: 包含 `.index.json` 和 `.item.json` 的目录
- `--dataset_name`: 数据集名称
- `--output_dir`: 输出目录
- `--category`: 商品类别名称（用于生成 prompt，如 "books", "movies"）
- `--max_valid_samples`, `--max_test_samples`: 限制验证/测试集大小（可选）

**输出文件结构：**
```
formatted/
├── train/
│   └── YourCategory_5_2016-10-2018-11.csv
├── valid/
│   └── YourCategory_5_2016-10-2018-11.csv
├── test/
│   └── YourCategory_5_2016-10-2018-11.csv
└── info/
    └── YourCategory_5_2016-10-2018-11.txt
```

**CSV 文件格式：**
```csv
user_id,history_item_title,item_title,history_item_id,item_id,history_item_sid,item_sid
A0,["商品1","商品2"],"商品3",[1,2],3,["[token1][token2]","[token3][token4]"],"[token5][token6]"
```

### 步骤 5：监督微调（SFT）

```bash
bash sft.sh
```

或直接运行：

```bash
torchrun --nproc_per_node 8 \
         sft.py \
         --base_model path/to/base/llm \
         --batch_size 1024 \
         --micro_batch_size 16 \
         --train_file ./data/YourDataset/formatted/train/YourCategory_5_2016-10-2018-11.csv \
         --eval_file ./data/YourDataset/formatted/valid/YourCategory_5_2016-10-2018-11.csv \
         --output_dir ./output/YourDataset/sft \
         --wandb_project YourProject \
         --wandb_run_name YourRunName \
         --category YourCategory \
         --train_from_scratch False \
         --seed 42 \
         --sid_index_path ./data/YourDataset/YourDataset.index.json \
         --item_meta_path ./data/YourDataset/YourDataset.item.json \
         --freeze_LLM False
```

**参数说明：**
- `--base_model`: 基础语言模型路径（如 Qwen, LLaMA）
- `--batch_size`, `--micro_batch_size`: 批次大小
- `--train_file`, `--eval_file`: 训练和验证 CSV 文件
- `--output_dir`: 模型输出目录
- `--category`: 商品类别（必须与 convert_dataset.py 中的一致）
- `--sid_index_path`: SID 索引文件路径
- `--item_meta_path`: 商品元数据文件路径
- `--freeze_LLM`: 是否冻结 LLM 参数（只训练新 token 嵌入）

### 步骤 6：强化学习（RL）

```bash
bash rl.sh
```

或直接运行：

```bash
HF_ENDPOINT=https://hf-mirror.com accelerate launch \
             --config_file ./config/zero2_opt.yaml \
             --num_processes 8 --main_process_port 29503 \
             rl.py \
             --model_path ./output/YourDataset/sft/final_checkpoint \
             --train_batch_size 64 \
             --eval_batch_size 128 \
             --num_train_epochs 2 \
             --gradient_accumulation_steps 2 \
             --train_file ./data/YourDataset/formatted/train/YourCategory_5_2016-10-2018-11.csv \
             --eval_file ./data/YourDataset/formatted/valid/YourCategory_5_2016-10-2018-11.csv \
             --info_file ./data/YourDataset/formatted/info/YourCategory_5_2016-10-2018-11.txt \
             --category YourCategory \
             --sample_train False \
             --eval_step 0.0999 \
             --reward_type ranking \
             --num_generations 16 \
             --beam_search True \
             --test_during_training False \
             --temperature 1.0 \
             --learning_rate 1e-5 \
             --beta 1e-3 \
             --output_dir ./output/YourDataset/rl \
             --wandb_run_name YourRLRun \
             --sid_index_path ./data/YourDataset/YourDataset.index.json \
             --item_meta_path ./data/YourDataset/YourDataset.item.json
```

**参数说明：**
- `--model_path`: SFT 阶段训练好的模型路径
- `--info_file`: 商品信息文件（包含 SID → 标题 → ID 映射）
- `--reward_type`: 奖励类型（`rule`, `ranking`, `semantic`, `sasrec`）
- `--num_generations`: 每个 prompt 生成的候选数量
- `--beam_search`: 是否使用束搜索
- `--beta`: KL 惩罚系数

### 步骤 7：评估

```bash
bash evaluate.sh \
     --exp_name ./output/YourDataset/rl/final_checkpoint \
     --test_data_path ./data/YourDataset/formatted/test/YourCategory_5_2016-10-2018-11.csv \
     --info_file ./data/YourDataset/formatted/info/YourCategory_5_2016-10-2018-11.txt \
     --category YourCategory \
     --num_beams 50 \
     --K 10
```

**参数说明：**
- `--exp_name`: 模型路径
- `--test_data_path`: 测试集 CSV 文件
- `--info_file`: 商品信息文件
- `--category`: 商品类别
- `--num_beams`: 束搜索大小
- `--K`: Top-K 评估（HR@K, NDCG@K）

## 快速开始示例

假设你有一个电影推荐数据集，包含：
- `movies.json`: 电影元数据
- `ratings.json`: 用户评分数据

### 1. 准备数据

```bash
# 创建数据目录
mkdir -p ./data/Movies

# 将数据转换为所需格式
# （需要编写简单的转换脚本，或使用 amazon18_data_process.py 的修改版本）
```

### 2. 生成嵌入

```bash
bash rq/text2emb/amazon_text2emb.sh \
     --dataset Movies \
     --root ./data/Movies \
     --plm_name qwen \
     --plm_checkpoint /path/to/Qwen2-7B-Instruct
```

### 3. 构建 SID

```bash
bash rq/rqvae.sh \
     --data_path ./data/Movies/Movies.emb-qwen-td.npy \
     --ckpt_dir ./output/Movies/rqvae \
     --lr 1e-3 \
     --epochs 10000 \
     --batch_size 20480
```

### 4. 生成索引

```bash
python rq/generate_indices.py \
     --dataset Movies \
     --data_dir ./data/Movies \
     --ckpt_dir ./output/Movies/rqvae
```

### 5. 转换格式

```bash
python convert_dataset.py \
     --data_dir ./data/Movies \
     --dataset_name Movies \
     --output_dir ./data/Movies/formatted \
     --category movies
```

### 6. 训练

```bash
# SFT
bash sft.sh  # 修改脚本中的路径和参数

# RL
bash rl.sh   # 修改脚本中的路径和参数
```

## 常见问题

### Q1: 我的数据集没有商品描述，只有标题怎么办？

在 `rq/text2emb/amazon_text2emb.py` 中，修改 `generate_text` 函数，只使用标题：

```python
def generate_text(item2feature, features):
    # 只使用 title，不使用 description
    item_text_list = []
    for item in item2feature:
        data = item2feature[item]
        text = []
        if 'title' in data:
            meta_value = clean_text(data['title'])
            cleaned = meta_value.strip()
            if cleaned != "":
                text.append(cleaned)
        # ... 其他代码
```

### Q2: 我的商品ID不是数字怎么办？

确保在 `.item.json` 和 `.index.json` 中使用字符串格式的 ID，并在交互文件中保持一致。

### Q3: 如何调整 SID 的长度？

在 RQ-VAE 训练时，调整 `--num_emb_list` 参数（每层的 codebook 大小）和层数。更多层数 = 更长的 SID。

### Q4: 内存不足怎么办？

- 减少批次大小（`--batch_size`, `--micro_batch_size`）
- 使用梯度累积（`--gradient_accumulation_steps`）
- 使用 DeepSpeed ZeRO（修改配置文件）
- 限制验证/测试集大小（`--max_valid_samples`, `--max_test_samples`）

### Q5: 如何自定义 reward 函数？

在 `rl.py` 中添加自定义 reward 函数，然后在 `reward_type` 参数中指定。

## 数据格式检查清单

在开始训练前，确保：

- [ ] `.item.json` 文件存在且格式正确
- [ ] `.train.inter`, `.valid.inter`, `.test.inter` 文件存在
- [ ] `.emb-*.npy` 嵌入文件已生成
- [ ] `.index.json` SID 索引文件已生成
- [ ] 转换后的 CSV 文件包含所有必需列
- [ ] `info/*.txt` 文件格式正确（SID \t 标题 \t ID）

## 参考

- 项目 README: `README.md`
- 数据处理脚本: `data/amazon18_data_process.py`
- 格式转换脚本: `convert_dataset.py`
- 训练脚本: `sft.py`, `rl.py`

