# MiniOneRec æ•°æ®æ–‡ä»¶è¯´æ˜

## ğŸ“‹ æ¦‚è¿°

MiniOneRec é¡¹ç›®ä½¿ç”¨ä¸¤ä¸ªæ ¸å¿ƒæ•°æ®æ–‡ä»¶æ¥ç®¡ç†å•†å“ä¿¡æ¯ï¼š

1. **`.item.json`** - å•†å“å…ƒæ•°æ®æ–‡ä»¶ï¼Œå­˜å‚¨å•†å“çš„æ–‡æœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æè¿°ã€å“ç‰Œç­‰ï¼‰
2. **`.index.json`** - å•†å“IDåˆ°è¯­ä¹‰ID (SID) çš„æ˜ å°„æ–‡ä»¶ï¼Œå­˜å‚¨æ¯ä¸ªå•†å“å¯¹åº”çš„è¯­ä¹‰æ ‡è¯†ç¬¦

è¿™ä¸¤ä¸ªæ–‡ä»¶é…åˆä½¿ç”¨ï¼Œå½¢æˆå®Œæ•´çš„å•†å“ä¿¡æ¯ä½“ç³»ï¼Œæ”¯æŒæ–‡æœ¬åµŒå…¥ç”Ÿæˆã€SID æ„å»ºå’Œæ¨¡å‹è®­ç»ƒã€‚

---

## ğŸ“ ç¬¬ä¸€éƒ¨åˆ†ï¼š`.item.json` æ–‡ä»¶è¯´æ˜

### æ¦‚è¿°

`.item.json` æ–‡ä»¶æ˜¯ **MiniOneRec é¡¹ç›®ä¸­çš„å•†å“å…ƒæ•°æ®æ–‡ä»¶**ï¼Œå­˜å‚¨äº†æ¯ä¸ªå•†å“çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æè¿°ã€å“ç‰Œã€åˆ†ç±»ç­‰æ–‡æœ¬ä¿¡æ¯ã€‚è¿™äº›ä¿¡æ¯ç”¨äºï¼š

1. **ç”Ÿæˆå•†å“æ–‡æœ¬åµŒå…¥**ï¼šå°†å•†å“æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
2. **æ„å»ºè¯­ä¹‰ ID (SID)**ï¼šé€šè¿‡æ–‡æœ¬åµŒå…¥ç”Ÿæˆå•†å“çš„è¯­ä¹‰æ ‡è¯†ç¬¦
3. **è®­ç»ƒè¯­è¨€å¯¹é½ä»»åŠ¡**ï¼šåœ¨ SFT é˜¶æ®µè®­ç»ƒæ¨¡å‹ç†è§£å•†å“æ–‡æœ¬å’Œ SID ä¹‹é—´çš„æ˜ å°„å…³ç³»

### æ–‡ä»¶ä½ç½®

åœ¨ä½ çš„é¡¹ç›®ä¸­ï¼Œè¿™ä¸¤ä¸ªæ–‡ä»¶ä½äºï¼š

- `data/Amazon/index/Office_Products.item.json` - åŠå…¬ç”¨å“ç±»å•†å“å…ƒæ•°æ®
- `data/Amazon/index/Industrial_and_Scientific.item.json` - å·¥ä¸šä¸ç§‘å­¦ç±»å•†å“å…ƒæ•°æ®

### æ–‡ä»¶ç»Ÿè®¡

| æ–‡ä»¶ | å•†å“æ•°é‡ | æ–‡ä»¶å¤§å° |
|------|---------|---------|
| `Office_Products.item.json` | **3,459** ä¸ªå•†å“ | ~2MB |
| `Industrial_and_Scientific.item.json` | **3,686** ä¸ªå•†å“ | ~2.2MB |

### æ–‡ä»¶æ ¼å¼

#### JSON ç»“æ„

```json
{
  "å•†å“ID": {
    "title": "å•†å“æ ‡é¢˜",
    "description": "å•†å“æè¿°ï¼ˆå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰",
    "brand": "å“ç‰Œåç§°",
    "categories": "åˆ†ç±»ä¿¡æ¯"
  },
  ...
}
```

#### å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|
| **å•†å“ID** | `string` | å•†å“çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆå­—ç¬¦ä¸²æ ¼å¼çš„æ•°å­—ï¼‰ | `"0"`, `"1"`, `"3458"` |
| **title** | `string` | å•†å“æ ‡é¢˜ | `"HP 74 Black & 75 Tri-color Original Ink Cartridges" |
| **description** | `string` æˆ– `list` | å•†å“æè¿°ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰ | `"å•†å“è¯¦ç»†æè¿°..."` æˆ– `["æè¿°1", "æè¿°2"]` |
| **brand** | `string` | å“ç‰Œåç§° | `"HP"`, `"AmazonBasics"` |
| **categories** | `string` | å•†å“åˆ†ç±»ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰ | `""` æˆ– `"åˆ†ç±»1,åˆ†ç±»2"` |

#### å®é™…ç¤ºä¾‹

**Office_Products.item.json ç¤ºä¾‹**ï¼š

```json
{
  "0": {
    "title": "HP 74 Black & 75 Tri-color Original Ink Cartridges, 2 Cartridges (CB335WN, CB337WN)",
    "description": "[\"HP 74 Black & 75 Tri-color Original Ink Cartridges, 2 Cartridges (CB335WN, CB337WN). HP 74 & 75 ink cartridges work with: HP Deskjet D4260...\", '...', '']",
    "brand": "HP",
    "categories": ""
  },
  "1": {
    "title": "AmazonBasics 6-Sheet Cross-Cut Paper and Credit Card Shredder",
    "description": "['An Amazon Brand.']",
    "brand": "AmazonBasics",
    "categories": ""
  }
}
```

**Industrial_and_Scientific.item.json ç¤ºä¾‹**ï¼š

```json
{
  "0": {
    "title": "SUPCO SPP6 Relay/Capacitor Hard Start Kit with 500% Increase Starting Torque",
    "description": "['Relay/CAPACITOR hard start kit 500% incr starting torque,increased compressor starting torque...']",
    "brand": "Sealed Unit Parts Co., Inc.",
    "categories": ""
  }
}
```

### åœ¨é¡¹ç›®ä¸­çš„ä½¿ç”¨

#### 1. æ–‡æœ¬åµŒå…¥ç”Ÿæˆé˜¶æ®µ

åœ¨ç”Ÿæˆå•†å“æ–‡æœ¬åµŒå…¥æ—¶ä½¿ç”¨ï¼š

```python
# rq/text2emb/amazon_text2emb.py
item2feature_path = os.path.join(args.root, f'{args.dataset}.item.json')

with open(item2feature_path, 'r') as f:
    item_features = json.load(f)
    
# æå–æ ‡é¢˜å’Œæè¿°
for item_id, features in item_features.items():
    title = features['title']
    description = features['description']
    # å°†æ–‡æœ¬ç¼–ç ä¸ºåµŒå…¥å‘é‡
```

#### 2. SFT è®­ç»ƒé˜¶æ®µ

åœ¨ç›‘ç£å¾®è°ƒæ—¶ä½¿ç”¨ï¼Œç”¨äºè®­ç»ƒè¯­è¨€å¯¹é½ä»»åŠ¡ï¼š

```python
# sft.py
train_data2 = SidItemFeatDataset(
    item_file=item_meta_path,  # æŒ‡å‘ .item.json æ–‡ä»¶
    index_file=sid_index_path,  # æŒ‡å‘ .index.json æ–‡ä»¶
    tokenizer=tokenizer,
    ...
)
```

**ä½œç”¨**ï¼š
- è®­ç»ƒ `sid2title` ä»»åŠ¡ï¼šç»™å®š SIDï¼Œç”Ÿæˆå•†å“æ ‡é¢˜
- è®­ç»ƒ `title2sid` ä»»åŠ¡ï¼šç»™å®šå•†å“æ ‡é¢˜ï¼Œç”Ÿæˆå¯¹åº”çš„ SID

#### 3. RL è®­ç»ƒé˜¶æ®µ

åœ¨å¼ºåŒ–å­¦ä¹ é˜¶æ®µä¹Ÿä½¿ç”¨å•†å“å…ƒæ•°æ®ï¼š

```python
# rl.py
train_data2 = RLTitle2SidDataset(
    item_file=item_meta_path,  # æŒ‡å‘ .item.json æ–‡ä»¶
    index_file=sid_index_path,
    ...
)
```

### å¦‚ä½•åˆ›å»º/ä¿®æ”¹ `.item.json` æ–‡ä»¶

#### æ–¹æ³• 1ï¼šä½¿ç”¨æ•°æ®é¢„å¤„ç†è„šæœ¬

å¦‚æœä½ æœ‰ Amazon é£æ ¼çš„æ•°æ®ï¼š

```bash
bash data/amazon18_data_process.sh \
     --dataset YourDataset \
     --output_path ./data/YourDataset \
     --metadata_file path/to/metadata.json \
     --reviews_file path/to/reviews.json
```

è„šæœ¬ä¼šè‡ªåŠ¨ç”Ÿæˆ `{dataset}.item.json` æ–‡ä»¶ã€‚

#### æ–¹æ³• 2ï¼šæ‰‹åŠ¨åˆ›å»º

å¦‚æœä½ éœ€è¦æ‰‹åŠ¨åˆ›å»ºï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```python
import json

item_data = {
    "0": {
        "title": "å•†å“æ ‡é¢˜",
        "description": "å•†å“æè¿°",  # æˆ– ["æè¿°1", "æè¿°2"]
        "brand": "å“ç‰Œåç§°",
        "categories": "åˆ†ç±»1,åˆ†ç±»2"  # å¯é€‰ï¼Œå¯ä»¥ä¸ºç©ºå­—ç¬¦ä¸²
    },
    "1": {
        "title": "å¦ä¸€ä¸ªå•†å“",
        "description": "å¦ä¸€ä¸ªå•†å“çš„æè¿°",
        "brand": "å¦ä¸€ä¸ªå“ç‰Œ",
        "categories": ""
    }
    # ... æ›´å¤šå•†å“
}

# ä¿å­˜ä¸º JSON
with open('YourDataset.item.json', 'w', encoding='utf-8') as f:
    json.dump(item_data, f, ensure_ascii=False, indent=2)
```

### æ³¨æ„äº‹é¡¹

1. **å•†å“IDæ ¼å¼**ï¼šå¿…é¡»ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼ï¼ˆ`"0"`, `"1"` è€Œä¸æ˜¯ `0`, `1`ï¼‰
2. **æè¿°å­—æ®µæ ¼å¼**ï¼šå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨
3. **å¿…éœ€å­—æ®µ**ï¼š`title` æ˜¯å¿…éœ€çš„ï¼Œç”¨äºç”Ÿæˆæ–‡æœ¬åµŒå…¥
4. **æ–‡ä»¶ç¼–ç **ï¼šä½¿ç”¨ UTF-8 ç¼–ç ä¿å­˜æ–‡ä»¶
5. **æ•°æ®å®Œæ•´æ€§**ï¼šç¡®ä¿æ‰€æœ‰åœ¨äº¤äº’æ•°æ®ä¸­å‡ºç°çš„å•†å“IDéƒ½åœ¨ `.item.json` ä¸­å­˜åœ¨

---

## ğŸ“ ç¬¬äºŒéƒ¨åˆ†ï¼š`.index.json` æ–‡ä»¶è¯´æ˜

### æ¦‚è¿°

`.index.json` æ–‡ä»¶å­˜å‚¨äº†**å•†å“IDåˆ°è¯­ä¹‰ID (SID) çš„æ˜ å°„å…³ç³»**ï¼Œæ˜¯ MiniOneRec é¡¹ç›®çš„æ ¸å¿ƒæ•°æ®æ–‡ä»¶ä¹‹ä¸€ã€‚æ¯ä¸ªå•†å“éƒ½è¢«æ˜ å°„åˆ°ä¸€ä¸ªç”± 3 ä¸ª token ç»„æˆçš„è¯­ä¹‰æ ‡è¯†ç¬¦ï¼Œç”¨äºåœ¨ç”Ÿæˆå¼æ¨èä¸­è¡¨ç¤ºå•†å“ã€‚

### æ–‡ä»¶æ ¼å¼

#### JSON ç»“æ„

```json
{
  "å•†å“ID": ["<a_xxx>", "<b_yyy>", "<c_zzz>"],
  ...
}
```

#### å®é™…ç¤ºä¾‹

```json
{
  "0": ["<a_102>", "<b_155>", "<c_18>"],
  "1": ["<a_225>", "<b_72>", "<c_187>"],
  "2": ["<a_130>", "<b_179>", "<c_0>"],
  ...
}
```

### SID æ ¼å¼è¯´æ˜

#### SID Token ç»“æ„

æ¯ä¸ªå•†å“çš„ SID ç”± **3 ä¸ª token** ç»„æˆï¼ˆå¯¹åº” 3 å±‚é‡åŒ–ï¼‰ï¼š

```
<a_{code1}><b_{code2}><c_{code3}>
```

**ç¤ºä¾‹**ï¼š
- `["<a_102>", "<b_155>", "<c_18>"]` â†’ å®Œæ•´ SID: `<a_102><b_155><c_18>`
- `["<a_255>", "<b_211>", "<c_133>"]` â†’ å®Œæ•´ SID: `<a_255><b_211><c_133>`

#### å±‚çº§å«ä¹‰

| å±‚çº§ | å‰ç¼€ | èŒƒå›´ | è¯´æ˜ |
|------|------|------|------|
| **ç¬¬1å±‚** | `<a_xxx>` | 0-255 | ç²—ç²’åº¦è¯­ä¹‰åˆ†ç±» |
| **ç¬¬2å±‚** | `<b_yyy>` | 0-255 | ä¸­ç­‰ç²’åº¦è¯­ä¹‰åˆ†ç±» |
| **ç¬¬3å±‚** | `<c_zzz>` | 0-255 | ç»†ç²’åº¦è¯­ä¹‰åˆ†ç±» |

#### ä¸ºä»€ä¹ˆæ˜¯ 3 å±‚ï¼Ÿ

- **ç¬¬1å±‚**ï¼šæ•è·å•†å“çš„å¤§ç±»åˆ«ï¼ˆå¦‚"åŠå…¬ç”¨å“"ã€"ç”µå­äº§å“"ï¼‰
- **ç¬¬2å±‚**ï¼šæ•è·å•†å“çš„å­ç±»åˆ«ï¼ˆå¦‚"æ‰“å°æœºè€—æ"ã€"æ–‡å…·"ï¼‰
- **ç¬¬3å±‚**ï¼šæ•è·å•†å“çš„ç»†åˆ†ç±»åˆ«ï¼ˆå¦‚"å¢¨ç›’"ã€"çº¸å¼ "ï¼‰

**ä¼˜åŠ¿**ï¼š
- å±‚æ¬¡åŒ–è¡¨ç¤ºï¼Œè¯­ä¹‰æ›´ä¸°å¯Œ
- å¯ä»¥æ”¯æŒ 256Â³ = 16,777,216 ç§ä¸åŒçš„ç»„åˆ
- å³ä½¿æœ‰ç¢°æ’ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æ·»åŠ å±‚çº§æ¥è§£å†³

---

## ğŸ”„ ç¬¬ä¸‰éƒ¨åˆ†ï¼š`.index.json` ç”Ÿæˆæµç¨‹è¯¦è§£

### å®Œæ•´ç”Ÿæˆæµç¨‹

```
1. å•†å“å…ƒæ•°æ® (.item.json)
   â†“
2. æ–‡æœ¬åµŒå…¥ç”Ÿæˆ (amazon_text2emb.py)
   â†“
3. åµŒå…¥å‘é‡æ–‡ä»¶ (.emb-{model}-td.npy)
   â†“
4. SID æ„å»ºæ¨¡å‹è®­ç»ƒ (RQ-VAE / RQ-Kmeans / RQ-Kmeans+)
   â†“
5. ç”Ÿæˆç´¢å¼•æ–‡ä»¶ (generate_indices.py / generate_indices_plus.py)
   â†“
6. å•†å“ID â†’ SID æ˜ å°„ (.index.json)
```

### è¯¦ç»†æ­¥éª¤

#### æ­¥éª¤ 1ï¼šå‡†å¤‡å•†å“å…ƒæ•°æ®

**è¾“å…¥æ–‡ä»¶**ï¼š`.item.json`ï¼ˆå·²åœ¨ç¬¬ä¸€éƒ¨åˆ†è¯´æ˜ï¼‰

#### æ­¥éª¤ 2ï¼šç”Ÿæˆæ–‡æœ¬åµŒå…¥

**è„šæœ¬**ï¼š`rq/text2emb/amazon_text2emb.py`

**ä½œç”¨**ï¼šå°†å•†å“æ–‡æœ¬ï¼ˆæ ‡é¢˜+æè¿°ï¼‰ç¼–ç ä¸ºå‘é‡è¡¨ç¤º

**æ‰§è¡Œå‘½ä»¤**ï¼š
```bash
bash rq/text2emb/amazon_text2emb.sh \
     --dataset Office_Products \
     --root ./data/Amazon/index \
     --plm_name qwen \
     --plm_checkpoint Qwen/Qwen2-7B-Instruct
```

**å¤„ç†æµç¨‹**ï¼š

```python
# 1. åŠ è½½å•†å“å…ƒæ•°æ®
item2feature = load_json(f'{dataset}.item.json')

# 2. æå–æ–‡æœ¬ï¼ˆæ ‡é¢˜ + æè¿°ï¼‰
for item_id, features in item2feature.items():
    text = features['title'] + " " + features['description']
    
# 3. ä½¿ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ Qwenï¼‰ç¼–ç 
embeddings = model.encode(texts)  # å½¢çŠ¶: [N, D]

# 4. ä¿å­˜ä¸º .npy æ–‡ä»¶
np.save(f'{dataset}.emb-qwen-td.npy', embeddings)
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `Office_Products.emb-qwen-td.npy` - å½¢çŠ¶: `[3459, 1024]` (3459ä¸ªå•†å“ï¼Œæ¯ä¸ª1024ç»´å‘é‡)
- `Industrial_and_Scientific.emb-qwen-td.npy` - å½¢çŠ¶: `[3686, 1024]`

**å…³é”®ç‚¹**ï¼š
- ä½¿ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ Qwenï¼‰å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
- æ¯ä¸ªå•†å“å¯¹åº”ä¸€ä¸ªå›ºå®šç»´åº¦çš„å‘é‡ï¼ˆå¦‚ 1024 ç»´ï¼‰
- å‘é‡æ•è·äº†å•†å“çš„è¯­ä¹‰ä¿¡æ¯

#### æ­¥éª¤ 3ï¼šè®­ç»ƒ SID æ„å»ºæ¨¡å‹

é€‰æ‹©ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š

##### æ–¹æ³• 1ï¼šRQ-VAEï¼ˆResidual Quantization VAEï¼‰

**è„šæœ¬**ï¼š`rq/rqvae.py`

**æ‰§è¡Œå‘½ä»¤**ï¼š
```bash
bash rq/rqvae.sh \
     --data_path ./data/Office_Products.emb-qwen-td.npy \
     --ckpt_dir ./output/Office_Products \
     --lr 1e-3 \
     --epochs 10000 \
     --batch_size 20480
```

**åŸç†**ï¼š
- ä½¿ç”¨æ®‹å·®é‡åŒ–ï¼ˆResidual Quantizationï¼‰å°†è¿ç»­å‘é‡ç¦»æ•£åŒ–
- é€šè¿‡å¤šå±‚é‡åŒ–å™¨ï¼Œæ¯å±‚é‡åŒ–æ®‹å·®
- æœ€ç»ˆå¾—åˆ°å¤šå±‚æ¬¡çš„ç¦»æ•£ä»£ç 

**æ¨¡å‹ç»“æ„**ï¼š
```
è¾“å…¥åµŒå…¥ (1024ç»´)
    â†“
ç¼–ç å™¨ (MLP: 2048â†’1024â†’512â†’256â†’128â†’64)
    â†“
æ®‹å·®é‡åŒ–å™¨ (RQ)
    â”œâ”€ ç¬¬1å±‚: 256ä¸ªç æœ¬
    â”œâ”€ ç¬¬2å±‚: 256ä¸ªç æœ¬  
    â””â”€ ç¬¬3å±‚: 256ä¸ªç æœ¬
    â†“
è¾“å‡º: [code1, code2, code3] (æ¯ä¸ªæ˜¯0-255çš„æ•´æ•°)
```

##### æ–¹æ³• 2ï¼šRQ-Kmeans

**è„šæœ¬**ï¼š`rq/rqkmeans_faiss.py`

**æ‰§è¡Œå‘½ä»¤**ï¼š
```bash
conda install faiss-gpu
python rq/rqkmeans_faiss.py --dataset Office_Products
```

**åŸç†**ï¼š
- ä½¿ç”¨ K-means èšç±»æ›¿ä»£ VAE çš„é‡åŒ–å™¨
- æ¯å±‚å¯¹æ®‹å·®è¿›è¡Œ K-means èšç±»
- æ›´ç®€å•ä½†å¯èƒ½ç¢°æ’ç‡è¾ƒé«˜

##### æ–¹æ³• 3ï¼šConstrained RQ-Kmeans

**è„šæœ¬**ï¼š`rq/rqkmeans_constrained.sh`

**æ‰§è¡Œå‘½ä»¤**ï¼š
```bash
pip install k-means-constrained polars
bash rq/rqkmeans_constrained.sh
```

**åŸç†**ï¼š
- åœ¨ RQ-Kmeans åŸºç¡€ä¸Šæ·»åŠ å¹³è¡¡çº¦æŸ
- ç¡®ä¿æ¯ä¸ªèšç±»ä¸­çš„æ ·æœ¬æ•°é‡ç›¸å¯¹å‡åŒ€
- é™ä½ç¢°æ’ç‡

##### æ–¹æ³• 4ï¼šRQ-Kmeans+ï¼ˆæ¨èï¼‰

**è„šæœ¬**ï¼š`rq/rqkmeans_plus.sh`

**æ‰§è¡Œå‘½ä»¤**ï¼š
```bash
pip install k-means-constrained polars
bash rq/rqkmeans_constrained.sh  # å…ˆè®­ç»ƒåŸºç¡€æ¨¡å‹
bash rq/rqkmeans_plus.sh         # å†è®­ç»ƒå¢å¼ºæ¨¡å‹
```

**åŸç†**ï¼š
- åœ¨ RQ-Kmeans åŸºç¡€ä¸Šæ·»åŠ æ®‹å·®è¿æ¥
- ç¼–ç å™¨ï¼š`Z = X + MLP(X)`ï¼ˆæ®‹å·®å¢å¼ºï¼‰
- æ€§èƒ½æ›´å¥½ï¼Œç¢°æ’ç‡æ›´ä½

**è¾“å‡º**ï¼š
- è®­ç»ƒå¥½çš„æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆ`.pth` æ–‡ä»¶ï¼‰
- å­˜å‚¨åœ¨ `--ckpt_dir` æŒ‡å®šçš„ç›®å½•

#### æ­¥éª¤ 4ï¼šç”Ÿæˆç´¢å¼•æ–‡ä»¶

æ ¹æ®ä½¿ç”¨çš„è®­ç»ƒæ–¹æ³•ï¼Œé€‰æ‹©å¯¹åº”çš„ç”Ÿæˆè„šæœ¬ï¼š

##### æ–¹æ³• Aï¼šRQ-VAE ç´¢å¼•ç”Ÿæˆ

**è„šæœ¬**ï¼š`rq/generate_indices.py`

**æ‰§è¡Œå‘½ä»¤**ï¼š
```bash
python rq/generate_indices.py \
     --data_path ./data/Office_Products.emb-qwen-td.npy \
     --ckpt_path ./output/Office_Products/best_model.pth \
     --output_dir ./data/Amazon/index
```

**å¤„ç†æµç¨‹**ï¼š

```python
# 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model = RQVAE(...)
model.load_state_dict(torch.load(ckpt_path))
model.eval()

# 2. åŠ è½½åµŒå…¥å‘é‡
embeddings = np.load(data_path)  # [N, D]

# 3. å¯¹æ¯ä¸ªå•†å“ç”Ÿæˆç´¢å¼•
all_indices = []
for batch in embeddings:
    # é€šè¿‡æ¨¡å‹è·å–é‡åŒ–ä»£ç 
    codes = model.get_indices(batch)  # [3] - ä¸‰ä¸ªå±‚æ¬¡çš„ä»£ç 
    
    # è½¬æ¢ä¸º SID token æ ¼å¼
    sid_tokens = [
        f"<a_{codes[0]}>",  # ç¬¬1å±‚
        f"<b_{codes[1]}>",  # ç¬¬2å±‚
        f"<c_{codes[2]}>"   # ç¬¬3å±‚
    ]
    all_indices.append(sid_tokens)

# 4. å¤„ç†ç¢°æ’ï¼ˆå¦‚æœæœ‰å¤šä¸ªå•†å“å¾—åˆ°ç›¸åŒçš„SIDï¼‰
while has_collisions(all_indices):
    # å¯¹ç¢°æ’çš„å•†å“ä½¿ç”¨ Sinkhorn-Knopp ç®—æ³•é‡æ–°åˆ†é…
    resolve_collisions(model, all_indices)

# 5. ä¿å­˜ä¸º JSON
index_dict = {str(i): tokens for i, tokens in enumerate(all_indices)}
json.dump(index_dict, open('Office_Products.index.json', 'w'))
```

##### æ–¹æ³• Bï¼šRQ-Kmeans+ ç´¢å¼•ç”Ÿæˆ

**è„šæœ¬**ï¼š`rq/generate_indices_plus.py`

**æ‰§è¡Œå‘½ä»¤**ï¼š
```bash
bash rq/generate_indices_plus.sh \
     --data_path ./data/Office_Products.emb-qwen-td.npy \
     --ckpt_path ./output/Office_Products/rqkmeans_plus/best_model.pth
```

**å¤„ç†æµç¨‹**ï¼š

```python
# 1. åŠ è½½æ¨¡å‹ï¼ˆå¸¦æ®‹å·®ç¼–ç å™¨ï¼‰
model = RQVAE(...)
model.encoder = ResidualEncoderWrapper(model.encoder)  # Z = X + MLP(X)
model.load_state_dict(torch.load(ckpt_path))

# 2. ç”Ÿæˆä»£ç 
all_codes = []
for batch in embeddings:
    z = model.encoder(batch)  # æ®‹å·®å¢å¼º
    codes = model.rq(z)       # é‡åŒ–
    all_codes.append(codes)    # [3] - ä¸‰ä¸ªå±‚æ¬¡çš„ä»£ç 

# 3. åº”ç”¨åç§»ï¼ˆ+1ï¼‰ä»¥åŒ¹é…å‚è€ƒé€»è¾‘
all_codes = all_codes + 1

# 4. ä½¿ç”¨ Polars å¤„ç†å»é‡
codes_df = pl.DataFrame({'codes': [list(c) for c in all_codes]})
codes_dedup = deal_with_deduplicate(codes_df)  # å¤„ç†ç¢°æ’

# 5. æ ¼å¼åŒ–ä¸º JSON
codes_json = {}
for doc_id, row in enumerate(codes_dedup.iter_rows()):
    token_list = []
    code_seq = row['codes']
    for level_idx, val in enumerate(code_seq):
        prefix = chr(97 + level_idx)  # 'a', 'b', 'c'
        token = f"<{prefix}_{val}>"
        token_list.append(token)
    codes_json[str(doc_id)] = token_list

# 6. ä¿å­˜
json.dump(codes_json, open('Office_Products.index.json', 'w'))
```

**å»é‡é€»è¾‘**ï¼ˆ`deal_with_deduplicate`ï¼‰ï¼š

```python
def deal_with_deduplicate(df):
    # å¦‚æœæŸä¸ªä»£ç åºåˆ—å‡ºç°å¤šæ¬¡ï¼ˆç¢°æ’ï¼‰
    # ä¸ºæ¯ä¸ªé‡å¤é¡¹æ·»åŠ é¢å¤–çš„å±‚çº§æ¥åŒºåˆ†
    df_with_index = df.with_row_index()
    
    result_df = df_with_index.with_columns(
        pl.when(pl.len().over("codes") > 1)  # å¦‚æœæœ‰ç¢°æ’
        .then(
            pl.col("codes").list.concat(
                pl.col("index").rank(method="ordinal").over("codes")
            )  # æ·»åŠ æ’åä½œä¸ºé¢å¤–å±‚çº§
        )
        .otherwise(pl.col("codes"))  # æ— ç¢°æ’åˆ™ä¿æŒåŸæ ·
    )
    
    return result_df
```

### å…³é”®æŠ€æœ¯ç»†èŠ‚

#### 1. æ®‹å·®é‡åŒ–ï¼ˆResidual Quantizationï¼‰

**åŸç†**ï¼š
```
åŸå§‹å‘é‡: X (1024ç»´)
    â†“
ç¬¬1å±‚é‡åŒ–: code1 = quantize(X) â†’ æ®‹å·®1 = X - decode(code1)
    â†“
ç¬¬2å±‚é‡åŒ–: code2 = quantize(æ®‹å·®1) â†’ æ®‹å·®2 = æ®‹å·®1 - decode(code2)
    â†“
ç¬¬3å±‚é‡åŒ–: code3 = quantize(æ®‹å·®2)
    â†“
æœ€ç»ˆä»£ç : [code1, code2, code3]
```

**ä¼˜åŠ¿**ï¼š
- æ¯å±‚é‡åŒ–æ®‹å·®ï¼Œé€æ­¥ç»†åŒ–
- å¯ä»¥æ›´ç²¾ç¡®åœ°è¡¨ç¤ºåŸå§‹å‘é‡
- å±‚æ¬¡åŒ–ç»“æ„ï¼Œè¯­ä¹‰æ›´æ¸…æ™°

#### 2. ç¢°æ’å¤„ç†

**é—®é¢˜**ï¼šå¤šä¸ªå•†å“å¯èƒ½å¾—åˆ°ç›¸åŒçš„ SID

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ³• Aï¼šSinkhorn-Knopp ç®—æ³•**ï¼ˆRQ-VAEï¼‰
```python
# å¯¹ç¢°æ’çš„å•†å“ï¼Œä½¿ç”¨ Sinkhorn-Knopp ç®—æ³•é‡æ–°åˆ†é…
# ç¡®ä¿æ¯ä¸ªå•†å“éƒ½æœ‰å”¯ä¸€çš„ SID
while has_collisions(all_indices):
    collision_items = get_collision_items(all_indices)
    # ä½¿ç”¨ SK ç®—æ³•é‡æ–°é‡åŒ–
    new_indices = model.get_indices(collision_items, use_sk=True)
    update_indices(all_indices, collision_items, new_indices)
```

**æ–¹æ³• Bï¼šPolars å»é‡**ï¼ˆRQ-Kmeans+ï¼‰
```python
# å¦‚æœä»£ç åºåˆ—é‡å¤ï¼Œæ·»åŠ é¢å¤–å±‚çº§
codes_df = pl.DataFrame({'codes': [list(c) for c in all_codes]})
codes_dedup = deal_with_deduplicate(codes_df)
# é‡å¤é¡¹ä¼šå¾—åˆ°é¢å¤–çš„å±‚çº§æ¥åŒºåˆ†
```

#### 3. æ¨¡å‹è®­ç»ƒç›®æ ‡

**RQ-VAE è®­ç»ƒç›®æ ‡**ï¼š
- **é‡å»ºæŸå¤±**ï¼š`L_recon = ||X - X_recon||Â²`
- **é‡åŒ–æŸå¤±**ï¼š`L_quant = ||sg(z) - e||Â² + ||z - sg(e)||Â²`
- **æ€»æŸå¤±**ï¼š`L = L_recon + Î» * L_quant`

**ç›®æ ‡**ï¼š
- æœ€å°åŒ–é‡å»ºè¯¯å·®
- æœ€å°åŒ–ç¢°æ’ç‡
- ç¡®ä¿æ¯ä¸ªå•†å“éƒ½æœ‰å”¯ä¸€çš„ SID

### å®é™…ç¤ºä¾‹

#### è¾“å…¥æ•°æ®

**å•†å“ 0**ï¼š
```json
{
  "title": "HP 74 Black & 75 Tri-color Original Ink Cartridges",
  "description": "HP 74 & 75 ink cartridges work with: HP Deskjet D4260..."
}
```

#### å¤„ç†æµç¨‹

1. **æ–‡æœ¬åµŒå…¥**ï¼š
   ```
   æ–‡æœ¬ â†’ Qwen æ¨¡å‹ â†’ [0.23, -0.45, 0.67, ..., 0.12] (1024ç»´å‘é‡)
   ```

2. **é‡åŒ–ç¼–ç **ï¼š
   ```
   åµŒå…¥å‘é‡ â†’ RQ-VAE æ¨¡å‹ â†’ [102, 155, 18] (3ä¸ªæ•´æ•°ä»£ç )
   ```

3. **è½¬æ¢ä¸º SID**ï¼š
   ```
   [102, 155, 18] â†’ ["<a_102>", "<b_155>", "<c_18>"]
   ```

4. **æœ€ç»ˆæ˜ å°„**ï¼š
   ```json
   {
     "0": ["<a_102>", "<b_155>", "<c_18>"]
   }
   ```

### å¿«é€Ÿç”Ÿæˆç¤ºä¾‹

#### å®Œæ•´æµç¨‹ï¼ˆRQ-Kmeans+ï¼‰

```bash
# 1. ç”Ÿæˆæ–‡æœ¬åµŒå…¥
bash rq/text2emb/amazon_text2emb.sh \
     --dataset Office_Products \
     --root ./data/Amazon/index \
     --plm_name qwen \
     --plm_checkpoint Qwen/Qwen2-7B-Instruct

# 2. è®­ç»ƒ RQ-Kmeansï¼ˆåŸºç¡€ï¼‰
bash rq/rqkmeans_constrained.sh \
     --data_path ./data/Amazon/index/Office_Products.emb-qwen-td.npy \
     --ckpt_dir ./output/Office_Products/rqkmeans

# 3. è®­ç»ƒ RQ-Kmeans+ï¼ˆå¢å¼ºï¼‰
bash rq/rqkmeans_plus.sh \
     --data_path ./data/Amazon/index/Office_Products.emb-qwen-td.npy \
     --ckpt_path ./output/Office_Products/rqkmeans/best_model.pth \
     --ckpt_dir ./output/Office_Products/rqkmeans_plus

# 4. ç”Ÿæˆç´¢å¼•æ–‡ä»¶
bash rq/generate_indices_plus.sh \
     --data_path ./data/Amazon/index/Office_Products.emb-qwen-td.npy \
     --ckpt_path ./output/Office_Products/rqkmeans_plus/best_model.pth

# è¾“å‡º: ./data/Amazon/index/Office_Products.index.json
```

---

## ğŸ”— ç¬¬å››éƒ¨åˆ†ï¼šæ–‡ä»¶å…³ç³»å’Œä½¿ç”¨

### æ–‡ä»¶å¯¹åº”å…³ç³»

| æ–‡ä»¶ç±»å‹ | æ–‡ä»¶ç¤ºä¾‹ | å†…å®¹ |
|---------|---------|------|
| **å•†å“å…ƒæ•°æ®** | `Office_Products.item.json` | å•†å“ID â†’ æ–‡æœ¬ä¿¡æ¯ |
| **æ–‡æœ¬åµŒå…¥** | `Office_Products.emb-qwen-td.npy` | å•†å“ID â†’ å‘é‡ (1024ç»´) |
| **æ¨¡å‹æ£€æŸ¥ç‚¹** | `best_model.pth` | è®­ç»ƒå¥½çš„ RQ-VAE æ¨¡å‹ |
| **SID æ˜ å°„** | `Office_Products.index.json` | å•†å“ID â†’ SID tokens |

### æ•°æ®æµç¨‹

```
.item.json (å•†å“å…ƒæ•°æ®)
    â†“
æ–‡æœ¬åµŒå…¥ç”Ÿæˆ (amazon_text2emb.py)
    â†“
.emb-{model}-td.npy (åµŒå…¥å‘é‡)
    â†“
SID æ„å»º (RQ-VAE / RQ-Kmeans)
    â†“
.index.json (å•†å“ID â†’ SID æ˜ å°„)
    â†“
æ•°æ®é›†è½¬æ¢ (convert_dataset.py)
    â†“
è®­ç»ƒæ•°æ® (CSV æ ¼å¼)
```

### å¯¹åº”å…³ç³»ç¤ºä¾‹

```
å•†å“ID "0" 
  â†’ .item.json: {"title": "...", "description": "..."}
  â†’ .emb-qwen-td.npy: [0.23, -0.45, ..., 0.12] (ç¬¬0è¡Œ)
  â†’ .index.json: ["<a_102>", "<b_155>", "<c_18>"]
```

### åœ¨è®­ç»ƒä¸­çš„ä½¿ç”¨

#### SFT é˜¶æ®µ

```python
# sft.py
train_data2 = SidItemFeatDataset(
    item_file=item_meta_path,      # .item.json æ–‡ä»¶
    index_file=sid_index_path,     # .index.json æ–‡ä»¶
    tokenizer=tokenizer,
    ...
)
```

**ä½œç”¨**ï¼š
- è®­ç»ƒ `sid2title` ä»»åŠ¡ï¼šç»™å®š SIDï¼Œç”Ÿæˆå•†å“æ ‡é¢˜
- è®­ç»ƒ `title2sid` ä»»åŠ¡ï¼šç»™å®šå•†å“æ ‡é¢˜ï¼Œç”Ÿæˆå¯¹åº”çš„ SID

#### RL é˜¶æ®µ

```python
# rl.py
train_data2 = RLTitle2SidDataset(
    item_file=item_meta_path,      # .item.json æ–‡ä»¶
    index_file=sid_index_path,     # .index.json æ–‡ä»¶
    ...
)
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ•°æ®ä¸€è‡´æ€§

- ç¡®ä¿ `.item.json` ä¸­çš„å•†å“IDä¸ `.index.json` ä¸­çš„å•†å“IDä¸€è‡´
- å•†å“IDå¿…é¡»ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼ï¼ˆ`"0"`, `"1"` è€Œä¸æ˜¯ `0`, `1`ï¼‰
- ç¡®ä¿æ‰€æœ‰åœ¨äº¤äº’æ•°æ®ä¸­å‡ºç°çš„å•†å“IDéƒ½åœ¨ä¸¤ä¸ªæ–‡ä»¶ä¸­å­˜åœ¨

### 2. ç¢°æ’ç‡

- **ç†æƒ³æƒ…å†µ**ï¼šç¢°æ’ç‡ä¸º 0ï¼ˆæ¯ä¸ªå•†å“éƒ½æœ‰å”¯ä¸€çš„ SIDï¼‰
- **å®é™…æƒ…å†µ**ï¼šå¯èƒ½æœ‰å°‘é‡ç¢°æ’ï¼Œé€šè¿‡å»é‡ç®—æ³•è§£å†³
- **æ£€æŸ¥ç¢°æ’**ï¼šç”Ÿæˆç´¢å¼•åæ£€æŸ¥ç¢°æ’ç»Ÿè®¡

### 3. æ¨¡å‹å‚æ•°

- `num_emb_list=[256, 256, 256]`ï¼šæ¯å±‚ 256 ä¸ªç æœ¬
- `e_dim=32`ï¼šç æœ¬åµŒå…¥ç»´åº¦
- `layers=[2048, 1024, 512, 256, 128, 64]`ï¼šç¼–ç å™¨å±‚å¤§å°

### 4. æ–‡ä»¶ç¼–ç 

- ä½¿ç”¨ **UTF-8** ç¼–ç ä¿å­˜æ–‡ä»¶
- ç¡®ä¿ä¸­æ–‡å­—ç¬¦æ­£ç¡®æ˜¾ç¤º

### 5. æ€§èƒ½ä¼˜åŒ–

- ä½¿ç”¨ GPU åŠ é€Ÿè®­ç»ƒå’Œæ¨ç†
- æ‰¹é‡å¤„ç†åµŒå…¥å‘é‡
- ä½¿ç”¨å¤šè¿›ç¨‹åŠ è½½æ•°æ®

---

## ğŸ“ æ€»ç»“

### `.item.json` æ–‡ä»¶

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **æ–‡ä»¶ç±»å‹** | JSON æ ¼å¼çš„å•†å“å…ƒæ•°æ®æ–‡ä»¶ |
| **ä¸»è¦ç”¨é€”** | å­˜å‚¨å•†å“æ–‡æœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æè¿°ã€å“ç‰Œç­‰ï¼‰ |
| **ä½¿ç”¨åœºæ™¯** | æ–‡æœ¬åµŒå…¥ç”Ÿæˆã€SFT è®­ç»ƒã€RL è®­ç»ƒ |
| **å¿…éœ€å­—æ®µ** | `title`ï¼ˆæ ‡é¢˜ï¼‰ |
| **æ¨èå­—æ®µ** | `description`ï¼ˆæè¿°ï¼‰ã€`brand`ï¼ˆå“ç‰Œï¼‰ |
| **ID æ ¼å¼** | å­—ç¬¦ä¸²æ ¼å¼çš„æ•°å­—ï¼ˆå¦‚ `"0"`, `"1"`ï¼‰ |

### `.index.json` æ–‡ä»¶

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **æ–‡ä»¶ç±»å‹** | JSON æ ¼å¼çš„æ˜ å°„æ–‡ä»¶ |
| **ä¸»è¦ç”¨é€”** | å­˜å‚¨å•†å“IDåˆ°è¯­ä¹‰ID (SID) çš„æ˜ å°„ |
| **ç”Ÿæˆæ–¹å¼** | é€šè¿‡ RQ-VAE/RQ-Kmeans ä»æ–‡æœ¬åµŒå…¥ç”Ÿæˆ |
| **SID æ ¼å¼** | 3 å±‚ tokenï¼š`["<a_xxx>", "<b_yyy>", "<c_zzz>"]` |
| **å…³é”®è¦æ±‚** | æ¯ä¸ªå•†å“å¿…é¡»æœ‰å”¯ä¸€çš„ SID |

### å…³é”®ç‚¹

- âœ… `.item.json` æ˜¯å•†å“å…ƒæ•°æ®æ–‡ä»¶ï¼ŒåŒ…å«å•†å“çš„æ–‡æœ¬ä¿¡æ¯
- âœ… `.index.json` å­˜å‚¨å•†å“IDåˆ°SIDçš„æ˜ å°„ï¼Œé€šè¿‡æ–‡æœ¬åµŒå…¥å’Œé‡åŒ–æ¨¡å‹ç”Ÿæˆ
- âœ… ä¸¤ä¸ªæ–‡ä»¶é…åˆä½¿ç”¨ï¼Œå½¢æˆå®Œæ•´çš„å•†å“ä¿¡æ¯ä½“ç³»
- âœ… åœ¨æ–‡æœ¬åµŒå…¥ç”Ÿæˆã€SFT è®­ç»ƒå’Œ RL è®­ç»ƒé˜¶æ®µéƒ½ä¼šä½¿ç”¨
- âœ… å•†å“IDå¿…é¡»ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼ï¼Œä¸”ä¸å…¶ä»–æ–‡ä»¶ä¿æŒä¸€è‡´
- âœ… SID æ˜¯å±‚æ¬¡åŒ–çš„è¯­ä¹‰æ ‡è¯†ç¬¦ï¼ˆ3 å±‚ï¼‰ï¼Œé€šè¿‡æ®‹å·®é‡åŒ–ç”Ÿæˆ

### ç›¸å…³æ–‡æ¡£

- **åŸºç¡€æ¨¡å‹è¯´æ˜**ï¼šå‚è€ƒ `åŸºç¡€æ¨¡å‹è¯´æ˜.md`
- **æ•°æ®å‡†å¤‡**ï¼šå‚è€ƒ `å…¶ä»–æ•°æ®é›†ä½¿ç”¨æŒ‡å—.md`
- **å®Œæ•´æµç¨‹**ï¼šå‚è€ƒ `README.md`

